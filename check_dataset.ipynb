{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "device = \"cuda:4\"\n",
    "\n",
    "from data.create_dataset import create_dataset\n",
    "\n",
    "dataset_configs = json.load(open('data/dataset_configs.json', 'r'))\n",
    "print(dataset_configs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class DirectSAM():\n",
    "\n",
    "    def __init__(self, model_name, resolution, device):\n",
    "        self.model = AutoModelForSemanticSegmentation.from_pretrained(model_name).to(device).half().eval()\n",
    "        self.processor = AutoImageProcessor.from_pretrained('chendelong/DirectSAM-1800px-0424')\n",
    "\n",
    "        self.processor.size['height'] = resolution\n",
    "        self.processor.size['width'] = resolution\n",
    "        self.resolution = resolution\n",
    "\n",
    "    def __call__(self, image):\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values.to(self.model.device).to(self.model.dtype)\n",
    "        logits = self.model(pixel_values=pixel_values).logits.float().cpu()\n",
    "\n",
    "        upsampled_logits = nn.functional.interpolate(\n",
    "            logits,\n",
    "            size=(self.resolution, self.resolution),\n",
    "            mode=\"bicubic\",\n",
    "        )\n",
    "        probabilities = torch.sigmoid(upsampled_logits).detach().numpy()[0,0]\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "resolution = 1024\n",
    "thickness = 3\n",
    "\n",
    "model = DirectSAM(\n",
    "    \"chendelong/DirectSAM-tiny-distilled-15ep-768px-0821\",\n",
    "    resolution, \n",
    "    device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name in ['ADE20k', 'EntitySeg', 'COCONut_relabeld_COCO_val', 'LoveDA', 'PascalPanopticParts', 'PartImageNet++']:\n",
    "for dataset_name in ['EntitySeg']:\n",
    "\n",
    "    dataset_config = dataset_configs[dataset_name]\n",
    "\n",
    "    dataset = create_dataset(dataset_config, split='validation', resolution=resolution, thickness=thickness)\n",
    "\n",
    "    print(dataset_config)\n",
    "    print(dataset_name)\n",
    "    print(len(dataset))\n",
    "\n",
    "    for i in range(5):\n",
    "        sample = dataset[random.randint(0, len(dataset)-1)]\n",
    "\n",
    "        if type(sample) == dict:\n",
    "            image = sample['image']\n",
    "            target = sample['label']\n",
    "        else:\n",
    "            image, target = sample\n",
    "\n",
    "        prob = model(image)\n",
    "\n",
    "        plt.figure(figsize=(30, 6))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(target)\n",
    "\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(prob)\n",
    "\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(prob > 0.5)\n",
    "\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
