{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import AutoModelForSemanticSegmentation, AutoImageProcessor\n",
    "import torch.nn as nn\n",
    "from model.directsam import DirectSAM\n",
    "from evaluation.metrics import recall_with_tolerance\n",
    "\n",
    "device = \"cuda:0\"\n",
    "\n",
    "from data.create_dataset import create_dataset\n",
    "\n",
    "dataset_configs = json.load(open('data/dataset_configs.json', 'r'))\n",
    "print(dataset_configs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 1024\n",
    "threshold = 0.3\n",
    "\n",
    "tolerance = resolution // 100 \n",
    "tolerance += tolerance % 2 == 0\n",
    "\n",
    "model = DirectSAM(\n",
    "    # \"chendelong/DirectSAM-1800px-0424\",\n",
    "    \"/home/dchenbs/workspace/DirectSAM/runs/directsam_pseudo_label_merged/0829-1210-1024px-from-chendelong_DirectSAM-1800px-0424/checkpoint-6000\",\n",
    "    resolution, \n",
    "    threshold,\n",
    "    device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def compare_boundaries(target, prediction, tolerance, linewidth, brightness=192):\n",
    "\n",
    "    target_blured = cv2.GaussianBlur(target.astype(np.float32), (tolerance, tolerance), 0) > 0\n",
    "    prediction_blured = cv2.GaussianBlur(prediction.astype(np.float32), (tolerance, tolerance), 0) > 0\n",
    "\n",
    "    gray = target * prediction_blured\n",
    "    red = target * (prediction_blured == 0)\n",
    "    blue = prediction * (target_blured == 0)\n",
    "\n",
    "    gray = cv2.GaussianBlur(gray.astype(np.float32), (linewidth, linewidth), 0) > 0\n",
    "    red = cv2.GaussianBlur(red.astype(np.float32), (linewidth, linewidth), 0) > 0\n",
    "    blue = cv2.GaussianBlur(blue.astype(np.float32), (linewidth, linewidth), 0) > 0\n",
    "\n",
    "    image = np.ones((target.shape[0], target.shape[1], 3)) * 255\n",
    "    image[gray] = [brightness, brightness, brightness]\n",
    "    image[red] = [brightness, 0, 0]\n",
    "    image[blue] = [0, 0, brightness]\n",
    "\n",
    "    image[:tolerance, :, :] = image[-tolerance:, :, :] = image[:, :tolerance, :] = image[:, -tolerance:, :] = 255\n",
    "\n",
    "    return image.astype(np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name in ['GTA5', 'DRAM', 'SOBA', 'UDA-Part', 'SeginW', 'CIHP', 'Fashionpedia', 'PartIT', 'PascalPanopticParts', 'SPIN', 'PartImageNet++', 'ADE20k', 'EntitySeg', 'LoveDA', 'COCONut_relabeld_COCO_val', 'COCONut-s', 'COCONut-b', 'COCO2017', 'LVIS']:\n",
    "for dataset_name in ['EntitySeg', 'PascalPanopticParts']:\n",
    "# for dataset_name in ['directsam_pseudo_label_merged']:\n",
    "# for dataset_name in ['COIFT', 'DIS5K-DIS-TR', 'DIS5K-DIS-VD', 'DUTS-TE', 'DUTS-TR', 'ecssd', 'fss_all', 'HRSOD', 'MSRA_10K', 'ThinObject5K']:\n",
    "# for dataset_name in list(dataset_configs.keys()):\n",
    "\n",
    "    dataset_config = dataset_configs[dataset_name]\n",
    "\n",
    "    dataset = create_dataset(dataset_config, split='validation', resolution=resolution, thickness=2)\n",
    "\n",
    "    print(dataset_config)\n",
    "    print(dataset_name)\n",
    "    print(len(dataset))\n",
    "\n",
    "\n",
    "    for i in tqdm.tqdm(range(5)):\n",
    "        # sample = dataset[random.randint(0, len(dataset)-1)]\n",
    "        sample = dataset[i]\n",
    "\n",
    "        if type(sample) == dict:\n",
    "            image = sample['image']\n",
    "            target = sample['label']\n",
    "        else:\n",
    "            image, target = sample\n",
    "\n",
    "        prediction, num_tokens = model(image)\n",
    "        recall = recall_with_tolerance(target, prediction, tolerance)\n",
    "\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        plt.title('Input image')\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(compare_boundaries(target, prediction, tolerance=tolerance, linewidth=3))\n",
    "        plt.title(f'Recall: {recall:.2f}')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(target, cmap='Reds')\n",
    "        plt.imshow(image, alpha=0.3)\n",
    "        plt.axis('off')\n",
    "        plt.title('Ground Truth Label')\n",
    "\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(prediction, cmap='Blues')\n",
    "        plt.imshow(image, alpha=0.3)\n",
    "        plt.title(f'DirectSAM Pseudo label ({num_tokens} tokens)')\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subobject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
